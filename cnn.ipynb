{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み\n",
    "\n",
    "mnistと呼ばれる有名な手書き文字（0~9）のデータセットを使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "    \n",
    "    \n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False, one_hot_label=True)\n",
    "# 0~255 の値をスケーリングする\n",
    "x_train, x_test = x_train / 255, x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)\n",
    "\n",
    "print(img.shape)\n",
    "img = img.reshape(28, 28)\n",
    "print(img.shape)\n",
    "\n",
    "# img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNとは\n",
    "\n",
    "**CNN(Convolution Nueral Network)**とは畳み込み(Convolution)層とプーリング層を持つ\n",
    "DNNです。\n",
    "\n",
    "従来のDNNと異なり、上述の２層を持っておりデータの**位置情報**を扱えるようになっているのが特徴です。\n",
    "\n",
    "この特徴からCNNは主に画像認識（クラス分類、オブジェクト検出、セグメンテーション）の分野でよく使われます。\n",
    "\n",
    "畳み込み(Convolution)層とプーリング層についてそれぞれ簡単に説明します。\n",
    "\n",
    "**畳み込み層**とはフィルタと呼ばれる小さな領域と画像の一部分との計算を行うことで、位置情報を含んだ情報として特徴量に変換します。\n",
    "\n",
    "またこのフィルタ計算はスライドしてすべての領域と計算を行うため画像のズレにも対応できます。\n",
    "（隅にある丸も真ん中にある丸も同じ丸だと認識できます。）\n",
    "\n",
    "これによって画像からこのあたりは赤っぽいとか尖った線があるなどの特徴をとらえることができます。\n",
    "\n",
    "**プーリング層**では情報の圧縮を行うような層で画像をデフォルメ化するような効果があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import im2col, col2im "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畳み込み層の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, output_c, filter_h, filter_w, stride = 1, pad = 0):\n",
    "        \"\"\"\n",
    "        Wは( filter_h * filter_w * input_channel, out_channel)\n",
    "        b は( 1, out_channel)\n",
    "        を想定\n",
    "        \"\"\"\n",
    "        # 重みとバイアスを設定\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        # その他変わらないパラメータを格納\n",
    "        self.stride, self.pad, self.output_c, self.filter_h, self.filter_w = stride, pad, output_c, filter_h, filter_w\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x, self.col = None, None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        W, b = self.params\n",
    "        stride, pad, output_c, filter_h, filter_w = self.stride, self.pad, self.output_c, self.filter_h, self.filter_w\n",
    "        \n",
    "        # なぜこの並び(N, C, H, W)なのか？  \n",
    "        # kerasに合わせてるのか？\n",
    "        if x.ndim == 4:\n",
    "            N, input_c, input_h, input_w = x.shape\n",
    "        elif x.ndim == 3:\n",
    "            N, input_h, input_w = x.shape\n",
    "            input_c = 1\n",
    "        else:\n",
    "            print(\"DAME!\")\n",
    "            print(x.shape)\n",
    "        \n",
    "        # 最終的な出力のサイズを算出\n",
    "        out_h = 1 + int((input_h + 2*pad - filter_h) / stride)\n",
    "        out_w = 1 + int((input_w + 2*pad - filter_w) / stride)\n",
    "        \n",
    "        # データを(N H W C)から(N*out_h*out_w, filter_h * filter_w * C)\n",
    "        col = im2col(x, self.filter_h, self.filter_w, self.stride, self.pad)\n",
    "        out = np.dot(col, W) + b\n",
    "        \n",
    "        # N, out_h, out_w, output_Cに整形\n",
    "        out = out.reshape(N, output_c, out_h, out_w)\n",
    "        \n",
    "        self.x, self.col = x, col\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        W, b = self.params\n",
    "        output_c, filter_h, filter_w = self.output_c, self.filter_h, self.filter_w\n",
    "        \n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, output_c)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        ## self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, W.T)\n",
    "        dx = col2im(dcol, self.x.shape, filter_h, filter_w, self.stride, self.pad)\n",
    "\n",
    "        return dx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#( filter_h * filter_w * input_channel, out_channel)\n",
    "#        b は( 1, out_channel)\n",
    "\n",
    "# 重みとバイアスの初期化\n",
    "W = 0.01 * np.random.randn(3 * 3 , 4)  # 3 * 3 * 3でない？\n",
    "b = np.zeros([1, 4])\n",
    "\n",
    "conv = Convolution(W, b, 4, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "       0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " img[14, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.85306113])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 25)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img.reshape(1, 28, 28, 1)\n",
    "\n",
    "im2col(img.reshape(1, 1, 28, 28), 5, 5, 1, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2296291892962214"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(out[0,0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-356-7b3cb692269f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-350-d2a3a7754da1>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;31m## self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "conv.backward(out).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プーリング層の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        # 更新パラメータはなし\n",
    "        self.params, self.grads = [], []\n",
    "        # 学習中変わらないパラメータを詰め込む\n",
    "        self.pool_h, self.pool_w, self.stride, self.pad = pool_h, pool_w, stride, pad\n",
    "        \n",
    "        self.x, self.arg_max = None, None\n",
    "\n",
    "    def forward(self, x):\n",
    "        pool_h, pool_w, stride, pad = self.pool_h, self.pool_w, self.stride, self.pad\n",
    "        # なぜこの並び(N, C, H, W)なのか？  \n",
    "        # kerasに合わせてるのか？\n",
    "        if x.ndim == 4:\n",
    "            N, input_c, input_h, input_w = x.shape\n",
    "        elif x.ndim == 3:\n",
    "            N, input_h, input_w = x.shape\n",
    "            input_c = 1\n",
    "\n",
    "        out_h = int(1 + (input_h - pool_h) / stride)\n",
    "        out_w = int(1 + (input_w - pool_w) / stride)\n",
    "\n",
    "        col = im2col(x, pool_h, pool_w, stride, pad)\n",
    "        col = col.reshape(-1, pool_h * pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, input_c).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        pool_h, pool_w, stride, pad = self.pool_h, self.pool_w, self.stride, self.pad\n",
    "        \n",
    "        x, arg_max = self.x, self.arg_max\n",
    "        \n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = pool_h * pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(arg_max.size), arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, x.shape, pool_h, pool_w, stride, pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 14, 14)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = Pooling(2, 2, 2)\n",
    "\n",
    "pool.forward(img.reshape(1, 1, 28, 28)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 28, 28)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.backward(pool.forward(img.reshape(1, 1, 28, 28))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "          0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "          0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "          0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "          0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "          0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "          0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "          0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "          0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "          0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "          0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "          0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "          0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "          0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "          0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "          0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "          0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "          0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "          0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "          0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "          0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "          0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "          0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "          0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "          0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "          0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "          0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "          0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "          0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "          0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        ]]]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.reshape((1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten層\n",
    "\n",
    "(N , C, H, W) から　(N , C * H * W)に 変換するだけの層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flat:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.input_shape = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        out = x.reshape(N, -1)\n",
    "        \n",
    "        self.input_shape = x.shape\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout = dout.reshape(self.input_shape)\n",
    "        \n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 28, 28)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat = Flat()\n",
    "flat_data = flat.forward(img.reshape((1, 1, 28, 28)))\n",
    "flat.backward(flat_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lenet構成のCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.138506455119824"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.random.randn(5 * 5 , 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as F\n",
    "import layers as L\n",
    "from gradient import numerical_gradient\n",
    "\n",
    "class LeNet:\n",
    "    def __init__(self, input_size, data_num, output_size):\n",
    "        \n",
    "        \n",
    "        # print(init_coef)\n",
    "        # 重みとバイアスの初期化\n",
    "        # 畳み込み層の重みパラメータの形状は\n",
    "        # filter_height * filter_width * input_channel, output_channel\n",
    "#         W1 = init_coef * np.random.randn(5 * 5 * 1, 6)\n",
    "#         b1 = np.zeros(6)\n",
    "#         W2 = init_coef * np.random.randn(5 * 5 * 6, 16)\n",
    "#         b2 = np.zeros(16)\n",
    "#         W3 = init_coef * np.random.randn(784, 120)\n",
    "#         b3 = np.zeros(120)\n",
    "#         W4 = init_coef * np.random.randn(120, 84)\n",
    "#         b4 = np.zeros(84)\n",
    "#         W5 = init_coef * np.random.randn(84, output_size)\n",
    "#         b5 = np.zeros(output_size)\n",
    "        limit = np.sqrt(1/data_num)\n",
    "        W1 = np.random.uniform(-limit, limit, (5 * 5 * 1, 6))\n",
    "        b1 = np.zeros(6)\n",
    "\n",
    "        W2 = np.random.uniform(-limit, limit, (5 * 5 * 6, 16))\n",
    "        b2 = np.zeros(16)\n",
    "\n",
    "        W3 = np.random.uniform(-limit, limit, (784, 120))\n",
    "        b3 = np.zeros(120)\n",
    "        W4 = np.random.uniform(-limit, limit, (120, 84))\n",
    "        b4 = np.zeros(84)\n",
    "        W5 = np.random.uniform(-limit, limit, (84, output_size))\n",
    "        b5 = np.zeros(output_size)\n",
    "        \n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            Convolution(W1, b1, 6, 5, 5, 1, 2),\n",
    "            L.Relu(),\n",
    "            Pooling(2, 2, 2),\n",
    "            Convolution(W2, b2, 16, 5, 5, 1, 2),\n",
    "            L.Relu(),\n",
    "            Pooling(2, 2, 2),\n",
    "            Flat(),\n",
    "            L.Affine(W3, b3),\n",
    "            L.Relu(),\n",
    "            L.Affine(W4, b4),\n",
    "            L.Relu(),\n",
    "            L.Affine(W5, b5),\n",
    "        ]\n",
    "        \n",
    "        self.loss_layer = L.SoftmaxWithLoss()\n",
    "        \n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "#             print(layer)\n",
    "#             print(x.shape)\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        score = self.predict(x)\n",
    "        loss = self.loss_layer.forward(score, t)\n",
    "        return loss\n",
    "        \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    ## 数値微分と誤差逆伝搬法による微分\n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.forward(x, t)\n",
    "        # loss_W = self.forward(x, t)\n",
    "        \n",
    "        grads = []\n",
    "        for params in self.params:\n",
    "            grads.append(numerical_gradient(loss_W, params))\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        # 設定\n",
    "        grads = []\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            grads.append(layer.grads)\n",
    "\n",
    "        return  grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 28, 28)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:100].reshape(-1, 1, 28, 28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | train loss : 2.3026  acc : 0.1348 | val_loss *** val_acc : 0.1137\n",
      "| epoch 2 | train loss : 2.3025  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 3 | train loss : 2.3024  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 4 | train loss : 2.3023  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 5 | train loss : 2.3022  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 6 | train loss : 2.3021  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 7 | train loss : 2.3020  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 8 | train loss : 2.3019  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 9 | train loss : 2.3018  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 10 | train loss : 2.3018  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 11 | train loss : 2.3017  acc : 0.1348 | val_loss *** val_acc : 0.1135\n",
      "| epoch 12 | train loss : 2.3016  acc : 0.1348 | val_loss *** val_acc : 0.1135\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-415-824663a9bdba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# if (iters+1) % 10 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mloss_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'| epoch %d | train loss : %.4f  acc : %.4f | val_loss *** val_acc : %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m# model.forward(x_test, t_test),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-296-8257e8f2f3ab>\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrue_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-413-b7d067839441>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#             print(layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#             print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-350-d2a3a7754da1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# データを(N H W C)から(N*out_h*out_w, filter_h * filter_w * C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim2col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/dive/dnn-scratch/util.py\u001b[0m in \u001b[0;36mim2col\u001b[0;34m(input_data, filter_h, filter_w, stride, pad)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optimizer as opt\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "max_epoch = 20\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "# データの読み込み、モデルとオプティマイザの生成\n",
    "x, t = x_train[:512].reshape(-1, 1, 28, 28) , t_train[:512]\n",
    "\n",
    "model = LeNet(input_size=784, data_num=x.shape[0], output_size=10)\n",
    "optimizer = opt.SGD(lr=learning_rate)\n",
    "\n",
    "# 学習で使用する変数\n",
    "data_size = len(x)\n",
    "max_iters = data_size // batch_size\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    # データのシャッフル\n",
    "    idx = np.random.permutation(data_size)\n",
    "    x = x[idx]\n",
    "    t = t[idx]\n",
    "    \n",
    "    for iters in range(max_iters):\n",
    "        batch_x = x[iters * batch_size : (iters + 1) * batch_size]\n",
    "        batch_t = t[iters * batch_size : (iters + 1) * batch_size]\n",
    "        \n",
    "        # 勾配を求め、　パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "\n",
    "        model.backward()\n",
    "\n",
    "        optimizer.update(model.params, model.grads)\n",
    "#         print(\"### START###\")\n",
    "#         for layer_params in model.params:\n",
    "#             print(layer_params.__class__)\n",
    "#             print(np.sum(layer_params))\n",
    "#             print(\"### \")\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "    # 定期的に学習経過を出力\n",
    "    # if (iters+1) % 10 == 0:\n",
    "    avg_loss = total_loss / loss_count\n",
    "    print('| epoch %d | train loss : %.4f  acc : %.4f | val_loss *** val_acc : %.4f' % (epoch + 1, avg_loss, accuracy_score(model, x, t), accuracy_score(model, x_test, t_test)))\n",
    "    # model.forward(x_test, t_test),\n",
    "    \n",
    "    loss_list.append(avg_loss)\n",
    "    total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "6\n",
      "2400\n",
      "16\n",
      "94080\n",
      "120\n",
      "10080\n",
      "84\n",
      "840\n",
      "10\n",
      "Total params\n",
      "107786\n"
     ]
    }
   ],
   "source": [
    "sum_count = 0\n",
    "for param in model.params:\n",
    "    sum_count += param.size\n",
    "    print(param.size)\n",
    "    \n",
    "print(\"Total params\")\n",
    "print(sum_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Convolution object at 0x12f1c7da0>\n",
      "<layers.Relu object at 0x12f1c7e10>\n",
      "<__main__.Pooling object at 0x12ec57dd8>\n",
      "<__main__.Convolution object at 0x12ec57ac8>\n",
      "<layers.Relu object at 0x12ec57550>\n",
      "<__main__.Pooling object at 0x12ec57320>\n",
      "<__main__.Flat object at 0x12ec57278>\n",
      "<layers.Affine object at 0x12ec571d0>\n",
      "<layers.Relu object at 0x12ec57198>\n",
      "<layers.Affine object at 0x12ec57160>\n",
      "<layers.Relu object at 0x12ec57208>\n",
      "<layers.Affine object at 0x12ec57128>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 6)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精度の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-311-81f20d87b0cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-239-170dee576f57>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/dive/dnn-scratch/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 値渡し\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred_label = np.argmax(model.predict(x_test.reshape(-1, 1, 28, 28)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = np.argmax(t_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7422"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_label == true_label) / pred_label.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(model, x, y):\n",
    "    pred_label = np.argmax(model.predict(x.reshape(-1, 1, 28, 28)), axis=1)\n",
    "    true_label = np.argmax(y, axis=1)\n",
    "    \n",
    "    return np.sum(pred_label == true_label) / pred_label.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model, x_train[:500], t_train[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7422"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model, x_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み、モデルとオプティマイザの生成\n",
    "x, t = x_train[:1000].reshape(-1, 1, 28, 28), t_train[:1000]\n",
    "\n",
    "network = LeNet(input_size=784, data_num=x.shape[0], output_size=10)\n",
    "\n",
    "x_batch = x_train[:3].reshape(-1, 1, 28, 28)\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kerasのmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 2.3134 - acc: 0.0860 - val_loss: 2.3058 - val_acc: 0.1202\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 2.3024 - acc: 0.1280 - val_loss: 2.2925 - val_acc: 0.1958\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 2.2856 - acc: 0.2280 - val_loss: 2.2779 - val_acc: 0.3124\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 2.2676 - acc: 0.3620 - val_loss: 2.2613 - val_acc: 0.3701\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 2.2448 - acc: 0.4200 - val_loss: 2.2347 - val_acc: 0.3735\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 2.2042 - acc: 0.4180 - val_loss: 2.1851 - val_acc: 0.3637\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 2.1263 - acc: 0.4120 - val_loss: 2.0856 - val_acc: 0.3582\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 1.9657 - acc: 0.4620 - val_loss: 1.8780 - val_acc: 0.4475\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.6408 - acc: 0.5960 - val_loss: 1.4787 - val_acc: 0.6284\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 1.0974 - acc: 0.7360 - val_loss: 0.9468 - val_acc: 0.7081\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.6853 - acc: 0.8120 - val_loss: 0.9332 - val_acc: 0.7346\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 6s 11ms/step - loss: 0.8878 - acc: 0.8020 - val_loss: 1.2768 - val_acc: 0.7294\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 1.0221 - acc: 0.7860 - val_loss: 1.0706 - val_acc: 0.7964\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.7323 - acc: 0.8560 - val_loss: 1.5154 - val_acc: 0.7124\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.7474 - acc: 0.8460 - val_loss: 1.3962 - val_acc: 0.7150\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.7451 - acc: 0.8260 - val_loss: 0.8397 - val_acc: 0.8016\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.5720 - acc: 0.8600 - val_loss: 0.9718 - val_acc: 0.7966\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.4921 - acc: 0.8540 - val_loss: 1.0327 - val_acc: 0.7863\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.3497 - acc: 0.9080 - val_loss: 0.7701 - val_acc: 0.8368\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.3350 - acc: 0.9160 - val_loss: 0.7060 - val_acc: 0.8415\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "num_classes  = 10\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "model.add(Conv2D(6, kernel_size=(5, 5),\n",
    "                 strides=(1, 1),\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                      strides=(2,2),\n",
    "                      padding='valid'))\n",
    "model.add(Conv2D(16, kernel_size=(5, 5),\n",
    "                 strides=(1, 1),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                      strides=(2,2),\n",
    "                      padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adadelta(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(lr=0.01, decay=0.0, momentum=1.0, nesterov=False),\n",
    "              #optimizer=keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 20 ##学習の回数\n",
    "# データの用意\n",
    "x, t = x_train[:500].reshape(-1, 28, 28, 1) , t_train[:500]\n",
    "\n",
    "history = model.fit(x, t,\n",
    "                    batch_size=batch_size, epochs=epochs,\n",
    "                    verbose=1, validation_data=(x_test.reshape(-1, 28, 28, 1), t_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 120)               94200     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 107,786\n",
      "Trainable params: 107,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "教師データ500枚に絞って2層のDNNでも**８０%弱**の精度になることが分かる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
